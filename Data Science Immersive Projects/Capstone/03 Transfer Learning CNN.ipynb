{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transfer learning\n",
    "\n",
    "Source: https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/\n",
    "\n",
    "Transfer learning is the process of utilising knowledge from a particular task/domain to model for another task/domain.  \n",
    "\n",
    "cap10\n",
    "\n",
    "One approach of transfer learning is the use of pre-trained model. In this capstone project, we will utilise Google's mobilenet ConvNet model and retrain the last layer of the model to classify our 17 groceries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Retraining the pre-trained model\n",
    "Retraining the model is as simple as loading up the model in your terminal, and specifying the images that you wish to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --how_many_training_steps=500 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\\n",
    "  --output_graph=tf_files/retrained_graph.pb \\\n",
    "  --output_labels=tf_files/retrained_labels.txt \\\n",
    "  --architecture=\"${ARCHITECTURE}\" \\\n",
    "  --image_dir=tf_files/grocery-photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would define 2 functions to classify our image. We would define the first function, load_graph, to load our rerained model. The second function, read_tensor_from_image_file, will return the value of the class based on the model specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def load_graph(model_file):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(model_file, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "def read_tensor_from_image_file(file_name,\n",
    "                                input_height=299,\n",
    "                                input_width=299,\n",
    "                                input_mean=0,\n",
    "                                input_std=255):\n",
    "    input_name = \"file_reader\"\n",
    "    output_name = \"normalized\"\n",
    "    file_reader = tf.read_file(file_name, input_name)\n",
    "    if file_name.endswith(\".png\"):\n",
    "        image_reader = tf.image.decode_png(\n",
    "        file_reader, channels=3, name=\"png_reader\")\n",
    "    elif file_name.endswith(\".gif\"):\n",
    "        image_reader = tf.squeeze(\n",
    "        tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n",
    "    elif file_name.endswith(\".bmp\"):\n",
    "        image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n",
    "    else:\n",
    "        image_reader = tf.image.decode_jpeg(\n",
    "        file_reader, channels=3, name=\"jpeg_reader\")\n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0)\n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(normalized)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Load the graph (model) and labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = load_graph('../tensorflow-for-poets-2/tf_files/retrained_graph.pb')\n",
    "labels = load_labels('../tensorflow-for-poets-2/tf_files/retrained_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_height=128\n",
    "input_width=128\n",
    "input_mean=0\n",
    "input_std=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer = \"input\"\n",
    "output_layer = \"final_result\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Classifying image #1, class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.68615\n",
      "10 0.119967\n",
      "5 0.103596\n",
      "16 0.0839199\n",
      "14 0.00328049\n"
     ]
    }
   ],
   "source": [
    "file_name= '../tensorflow-for-poets-2/tf_files/augment/class0.jpg'\n",
    "t = read_tensor_from_image_file(\n",
    "      file_name,\n",
    "      input_height=input_height,\n",
    "      input_width=input_width,\n",
    "      input_mean=input_mean,\n",
    "      input_std=input_std)\n",
    "\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "    })\n",
    "    results = np.squeeze(results)\n",
    "\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "\n",
    "for i in top_k:\n",
    "    print(labels[i], results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Classifying image #2, class 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.982893\n",
      "14 0.00429732\n",
      "12 0.00390242\n",
      "10 0.00373618\n",
      "11 0.00329298\n"
     ]
    }
   ],
   "source": [
    "file_name= '../tensorflow-for-poets-2/tf_files/augment/class5.jpg'\n",
    "t = read_tensor_from_image_file(\n",
    "      file_name,\n",
    "      input_height=input_height,\n",
    "      input_width=input_width,\n",
    "      input_mean=input_mean,\n",
    "      input_std=input_std)\n",
    "\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "    })\n",
    "    results = np.squeeze(results)\n",
    "\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "\n",
    "for i in top_k:\n",
    "    print(labels[i], results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Classifying image #3, class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.450499\n",
      "11 0.270105\n",
      "13 0.13487\n",
      "15 0.0740191\n",
      "16 0.0211695\n"
     ]
    }
   ],
   "source": [
    "file_name= '../tensorflow-for-poets-2/tf_files/augment/class3.jpg'\n",
    "t = read_tensor_from_image_file(\n",
    "      file_name,\n",
    "      input_height=input_height,\n",
    "      input_width=input_width,\n",
    "      input_mean=input_mean,\n",
    "      input_std=input_std)\n",
    "\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "    })\n",
    "    results = np.squeeze(results)\n",
    "\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "\n",
    "for i in top_k:\n",
    "    print(labels[i], results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Image classification using deep learning can have significant impacts on society. In order to build a successful image classifier, we would need to establish a robust model for classification. The robustness of the model can be tweaked by the various hyper-parameters in the particular model of choice.  \n",
    "\n",
    "In this project, we have explored using the vanilla ConvNet architecture as well as a pre-trained ConvNet architecture made available by Google through transfer learning. In the vanilla ConvNet architecture, we have seen how we could tweak the architecture based on our preferences. On the other hand, we have also observed from transfer learning, the ease at which businesses can employ pre-existing models to help with their image classification problems.  \n",
    "\n",
    "In my personal opinion, I would advise businesses to take a look at their dataset before considering to build their own model for classification. Businesses can then pick and choose their best model based on their needs. Here are some advantages of both methods:  \n",
    "  \n",
    "  \n",
    "**1. Build ConvNet from scratch**\n",
    "- Full control of hyper-parameters\n",
    "- Full control of trainable features, depth and complexity of the model  \n",
    "\n",
    "**2.  Transfer learning **\n",
    "- Easy to apply\n",
    "- Models from different domains may be applicable to business use cases from differing domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future work\n",
    "1. Explore other techniques to classify images: Support Vector Machines, Fuzzy measures and Genetic Algorithms\n",
    "2. Build application for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
