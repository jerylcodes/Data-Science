{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 3\n",
    "\n",
    "### Regression and Classification with the Ames Housing Data\n",
    "\n",
    "---\n",
    "\n",
    "You have just joined a new \"full stack\" real estate company in Ames, Iowa. The strategy of the firm is two-fold:\n",
    "- Own the entire process from the purchase of the land all the way to sale of the house, and anything in between.\n",
    "- Use statistical analysis to optimize investment and maximize return.\n",
    "\n",
    "The company is still small, and though investment is substantial the short-term goals of the company are more oriented towards purchasing existing houses and flipping them as opposed to constructing entirely new houses. That being said, the company has access to a large construction workforce operating at rock-bottom prices.\n",
    "\n",
    "This project uses the [Ames housing data recently made available on kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 1. Estimating the value of homes from fixed characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "Your superiors have outlined this year's strategy for the company:\n",
    "1. Develop an algorithm to reliably estimate the value of residential houses based on *fixed* characteristics.\n",
    "2. Identify characteristics of houses that the company can cost-effectively change/renovate with their construction team.\n",
    "3. Evaluate the mean dollar value of different renovations.\n",
    "\n",
    "Then we can use that to buy houses that are likely to sell for more than the cost of the purchase plus renovations.\n",
    "\n",
    "Your first job is to tackle #1. You have a dataset of housing sale data with a huge amount of features identifying different aspects of the house. The full description of the data features can be found in a separate file:\n",
    "\n",
    "    housing.csv\n",
    "    data_description.txt\n",
    "    \n",
    "You need to build a reliable estimator for the price of the house given characteristics of the house that cannot be renovated. Some examples include:\n",
    "- The neighborhood\n",
    "- Square feet\n",
    "- Bedrooms, bathrooms\n",
    "- Basement and garage space\n",
    "\n",
    "and many more. \n",
    "\n",
    "Some examples of things that **ARE renovate-able:**\n",
    "- Roof and exterior features\n",
    "- \"Quality\" metrics, such as kitchen quality\n",
    "- \"Condition\" metrics, such as condition of garage\n",
    "- Heating and electrical components\n",
    "\n",
    "and generally anything you deem can be modified without having to undergo major construction on the house.\n",
    "\n",
    "---\n",
    "\n",
    "**Your goals:**\n",
    "1. Perform any cleaning, feature engineering, and EDA you deem necessary.\n",
    "- Be sure to remove any houses that are not residential from the dataset.\n",
    "- Identify **fixed** features that can predict price.\n",
    "- Train a model on pre-2010 data and evaluate its performance on the 2010 houses.\n",
    "- Characterize your model. How well does it perform? What are the best estimates of price?\n",
    "\n",
    "> **Note:** The EDA and feature engineering component to this project is not trivial! Be sure to always think critically and creatively. Justify your actions! Use the data description file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File ./housing.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cae39ab083b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhouse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./housing.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File ./housing.csv does not exist"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "house = pd.read_csv('./housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n",
    "house.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop columns with lots of null values : Alley, FireplaceQu, PoolQC, Fence, MiscFeature\n",
    "house.drop(inplace=True, axis=1, labels=['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove non-residential housing\n",
    "house_res = house[~house['MSZoning'].isin(['A','C','I','C (all)'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_res.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Determining fixed characteristics\n",
    "Based on the data descriptiion file, fixed characteristics are as follows:\n",
    "***\n",
    "\n",
    "\n",
    "MSSubClass: Identifies the type of dwelling involved in the sale.\t\n",
    "\n",
    "MSZoning: Identifies the general zoning classification of the sale.\n",
    "\t\t\n",
    "LotFrontage: Linear feet of street connected to property\n",
    "\n",
    "LotArea: Lot size in square feet\n",
    "\n",
    "LotShape: General shape of property\n",
    "\n",
    "LandContour: Flatness of the property\n",
    "\n",
    "Utilities: Type of utilities available\n",
    "\n",
    "LotConfig: Lot configuration\n",
    "\n",
    "LandSlope: Slope of property\n",
    "\n",
    "Neighborhood: Physical locations within Ames city limits\n",
    "\n",
    "Condition1: Proximity to various conditions\n",
    "\n",
    "Condition2: Proximity to various conditions (if more than one is present)\n",
    "\n",
    "BldgType: Type of dwelling\n",
    "\n",
    "HouseStyle: Style of dwelling\n",
    "\n",
    "YearBuilt: Original construction date\n",
    "\n",
    "YearRemodAdd: Remodel date (same as construction date if no remodeling or additions)\n",
    "\n",
    "MasVnrArea: Masonry veneer area in square feet\n",
    "\n",
    "BsmtFinSF1: Type 1 finished square feet\n",
    "\n",
    "BsmtFinSF2: Type 2 finished square feet\n",
    "\n",
    "TotalBsmtSF: Total square feet of basement area\n",
    "\n",
    "1stFlrSF: First Floor square feet\n",
    " \n",
    "2ndFlrSF: Second floor square feet\n",
    "\n",
    "LowQualFinSF: Low quality finished square feet (all floors)\n",
    "\n",
    "GrLivArea: Above grade (ground) living area square feet\n",
    "\n",
    "BsmtFullBath: Basement full bathrooms\n",
    "\n",
    "BsmtHalfBath: Basement half bathrooms\n",
    "\n",
    "FullBath: Full bathrooms above grade\n",
    "\n",
    "HalfBath: Half baths above grade\n",
    "\n",
    "Bedroom: Bedrooms above grade (does NOT include basement bedrooms)\n",
    "\n",
    "Kitchen: Kitchens above grade\n",
    "\n",
    "TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "\n",
    "GarageType: Garage location\n",
    "\n",
    "GarageYrBlt: Year garage was built\n",
    "\n",
    "GarageCars: Size of garage in car capacity\n",
    "\n",
    "GarageArea: Size of garage in square feet\n",
    "\n",
    "WoodDeckSF: Wood deck area in square feet\n",
    "\n",
    "OpenPorchSF: Open porch area in square feet\n",
    "\n",
    "EnclosedPorch: Enclosed porch area in square feet\n",
    "\n",
    "3SsnPorch: Three season porch area in square feet\n",
    "\n",
    "ScreenPorch: Screen porch area in square feet\n",
    "\n",
    "PoolArea: Pool area in square feet\n",
    "\n",
    "MiscVal: $Value of miscellaneous feature\n",
    "\n",
    "MoSold: Month Sold (MM)\n",
    "\n",
    "YrSold: Year Sold (YYYY)\n",
    "\n",
    "SaleType: Type of sale\n",
    "\n",
    "SaleCondition: Condition of sale\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Unfixed\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Street: Type of road access to property\n",
    "\n",
    "Alley: Type of alley access to property\n",
    "\n",
    "OverallQual: Rates the overall material and finish of the house\n",
    "\n",
    "OverallCond: Rates the overall condition of the house\n",
    "\n",
    "RoofStyle: Type of roof\n",
    "\n",
    "RoofMatl: Roof material\n",
    "\n",
    "Exterior1st: Exterior covering on house\n",
    "\n",
    "Exterior2nd: Exterior covering on house (if more than one material)\n",
    "\n",
    "MasVnrType: Masonry veneer type\n",
    "\n",
    "ExterQual: Evaluates the quality of the material on the exterior \n",
    "\t\t\n",
    "ExterCond: Evaluates the present condition of the material on the exterior\n",
    "\n",
    "Foundation: Type of foundation\n",
    "\n",
    "BsmtQual: Evaluates the height of the basement\n",
    "\n",
    "BsmtCond: Evaluates the general condition of the basement\n",
    "\n",
    "BsmtExposure: Refers to walkout or garden level walls\n",
    "\n",
    "BsmtFinType1: Rating of basement finished area\n",
    "\n",
    "BsmtFinType2: Rating of basement finished area (if multiple types)\n",
    "\n",
    "BsmtUnfSF: Unfinished square feet of basement area\n",
    "\n",
    "Heating: Type of heating\n",
    "\n",
    "HeatingQC: Heating quality and condition\n",
    "\n",
    "CentralAir: Central air conditioning\n",
    "\n",
    "Electrical: Electrical system\n",
    "\t\t\n",
    "KitchenQual: Kitchen quality\n",
    "       \t\n",
    "\n",
    "Functional: Home functionality (Assume typical unless deductions are warranted)\n",
    "\t\t\n",
    "Fireplaces: Number of fireplaces\n",
    "\n",
    "FireplaceQu: Fireplace quality\n",
    "\t\t\n",
    "\t\t\n",
    "GarageFinish: Interior finish of the garage\n",
    "\n",
    "GarageQual: Garage quality\n",
    "\n",
    "GarageCond: Garage condition\n",
    "\t\t\n",
    "PavedDrive: Paved driveway\n",
    "\n",
    "PoolQC: Pool quality\n",
    "\t\t\n",
    "Fence: Fence quality\n",
    "\n",
    "MiscFeature: Miscellaneous feature not covered in other categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in house_res.columns:\n",
    "   # fill NaN values with mean\n",
    "    if house_res[f].dtype == 'float64':\n",
    "        house_res[f][np.isnan(house_res[f])] = house_res[f].mean()\n",
    "    elif house_res[f].dtype == 'int64':\n",
    "        house_res[f][np.isnan(house_res[f])] = house_res[f].mean()\n",
    "# fill NaN values with most occured value\n",
    "    elif house_res[f].dtype == 'object':\n",
    "        house_res[f][house_res[f] != house_res[f]] = house_res[f].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixed_char = ['Id', 'SalePrice', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', \\\n",
    "              'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', \\\n",
    "              'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', \\\n",
    "              'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', \\\n",
    "              '1stFlrSF', '2ndFlrSF', 'LowQualFinSF' ,'GrLivArea', 'BsmtFullBath', \\\n",
    "              'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', \\\n",
    "              'GarageType', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \\\n",
    "              'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea' ,'MiscVal', 'MoSold', 'YrSold', \\\n",
    "              'SaleType', 'SaleCondition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_res1 = house_res.loc[:,fixed_char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use patsy dmatrices to dummify categorical variables\n",
    "import patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns to dummify (categorical/string/object columns)\n",
    "house_res1.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_res1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum all porch areas into new column\n",
    "house_res1['porch_area'] = house_res1.loc[:,['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch']].sum(axis=1)\n",
    "house_res1 = house_res1.drop(['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that have aggregate columns, like totalbasement SF, GrLivArea etc\n",
    "house_res1 = house_res1.drop(['Id','BsmtFinSF1','BsmtFinSF2', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF'], axis=1)\n",
    "house_res1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol = ['MSSubClass', 'MSZoning', 'LotShape', 'LandContour', 'Utilities', 'LotConfig','LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\\\n",
    "       'BldgType', 'HouseStyle', 'YearRemodAdd', 'BsmtFullBath', 'BsmtHalfBath',\\\n",
    "       'FullBath', 'HalfBath', 'TotRmsAbvGrd','BedroomAbvGr','KitchenAbvGr',\\\n",
    "       'GarageType', 'GarageYrBlt', 'GarageCars', 'MoSold', 'YrSold',\\\n",
    "       'SaleType', 'SaleCondition']\n",
    "for f in catcol:\n",
    "    sns.barplot(x=house_res1[f].value_counts().index, y= house_res1[f].value_counts())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop categorical columns with low variance according to countplots\n",
    "house_res1 = house_res1.drop(['Utilities', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'YearRemodAdd', 'BsmtHalfBath', 'KitchenAbvGr', 'GarageYrBlt', 'SaleType','SaleCondition'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_res1['BsmtFullBath_0'] = house_res1['BsmtFullBath'].map(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_res1['fullbath2<'] = house_res1['FullBath'].map(lambda x: 1 if x<2 else 0)\n",
    "house_res1['halfbath_0'] = house_res1['HalfBath'].map(lambda x: 1 if x==0 else 0)\n",
    "# house_res1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_res1 = house_res1.drop(['BsmtFullBath', 'FullBath', 'HalfBath'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean num columns\n",
    "house_res1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# near zero variance\n",
    "\n",
    "def nearZeroVariance(X, freqCut = 95 / 5, uniqueCut = 10):\n",
    "    '''\n",
    "    Determine predictors with near zero or zero variance.\n",
    "    Inputs:\n",
    "    X: pandas data frame\n",
    "    freqCut: the cutoff for the ratio of the most common value to the second most common value\n",
    "    uniqueCut: the cutoff for the percentage of distinct values out of the number of total samples\n",
    "    Returns a tuple containing a list of column names: (zeroVar, nzVar)\n",
    "    '''\n",
    "\n",
    "    colNames = X.columns.values.tolist()\n",
    "    freqRatio = dict()\n",
    "    uniquePct = dict()\n",
    "\n",
    "    for names in colNames:\n",
    "        counts = (\n",
    "            (X[names])\n",
    "            .value_counts()\n",
    "            .sort_values(ascending = False)\n",
    "            .values\n",
    "            )\n",
    "\n",
    "        if len(counts) == 1:\n",
    "            freqRatio[names] = -1\n",
    "            uniquePct[names] = (len(counts) / len(X[names])) * 100\n",
    "            continue\n",
    "\n",
    "        freqRatio[names] = counts[0] / counts[1]\n",
    "        uniquePct[names] = (len(counts) / len(X[names])) * 100\n",
    "\n",
    "    zeroVar = list()\n",
    "    nzVar = list()\n",
    "    for k in uniquePct.keys():\n",
    "        if freqRatio[k] == -1:\n",
    "            zeroVar.append(k)\n",
    "\n",
    "        if uniquePct[k] < uniqueCut and freqRatio[k] > freqCut:\n",
    "            nzVar.append(k)\n",
    "\n",
    "    return(zeroVar, nzVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zerovartest = house_res1.loc[:,['LotFrontage','LotArea','MasVnrArea', 'TotalBsmtSF','GrLivArea',\\\n",
    "                                'GarageArea','WoodDeckSF', 'PoolArea', 'MiscVal']]\n",
    "nearZeroVariance(zerovartest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_res1 = house_res1.drop(['MasVnrArea', 'PoolArea', 'MiscVal'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_res1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_res1 = pd.get_dummies(house_res1, columns=['MSSubClass', 'MSZoning','LotShape', 'LandContour',\\\n",
    "                                                 'LotConfig', 'Neighborhood','HouseStyle', 'BedroomAbvGr',\\\n",
    "                                                 'TotRmsAbvGrd', 'GarageType', 'GarageCars','MoSold'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_res1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindf = house_res1[house_res1['YrSold']!=2010]\n",
    "testdf = house_res1[house_res1['YrSold']==2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "y = traindf['SalePrice'].values\n",
    "X = traindf.drop(['SalePrice','YrSold'],axis=1)\n",
    "Xs = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lasso = LassoCV(n_alphas=500, cv=10, verbose=1)\n",
    "optimal_lasso.fit(Xs, y)\n",
    "\n",
    "print optimal_lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=optimal_lasso.alpha_)\n",
    "\n",
    "lasso_scores = cross_val_score(lasso, Xs, y, cv=10)\n",
    "\n",
    "print lasso_scores\n",
    "print np.mean(lasso_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs = pd.DataFrame({'variable':X.columns,\n",
    "                            'coef':lasso.coef_,\n",
    "                            'abs_coef':np.abs(lasso.coef_)})\n",
    "\n",
    "lasso_coefs.sort_values('abs_coef', inplace=True, ascending=False)\n",
    "\n",
    "lasso_coefs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Percent variables zeroed out:', np.sum((lasso.coef_ == 0))/float(Xs.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs[lasso_coefs['abs_coef']==0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicting test\n",
    "y1 = testdf['SalePrice'].values\n",
    "X1 = testdf.drop(['SalePrice','YrSold'],axis=1)\n",
    "Xs1 = ss.transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.predict(Xs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_scores = cross_val_score(lasso, Xs1, y1, cv=10)\n",
    "\n",
    "print lasso_scores\n",
    "print np.mean(lasso_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# workings\n",
    "# Utilities LandSlope Condition1 Condition2 BldgType, 'YearRemodAdd', 'BsmtHalfBath', 'KitchenAbvGr', GarageYrBlt, 'SaleType','SaleCondition'\n",
    "# 'BsmtFullBath(0, >0)', FullBath(<2, >2), HalfBath(0,>0)\n",
    "\n",
    "# Y'SalePrice', u'MSSubClass', u'MSZoning', NUM'LotFrontage',\n",
    "#        NUM'LotArea', u'LotShape', u'LandContour', u'Utilities', u'LotConfig',\n",
    "#        u'LandSlope', u'Neighborhood', u'Condition1', u'Condition2',\n",
    "#        u'BldgType', u'HouseStyle', u'YearRemodAdd', NUM'MasVnrArea'DD,\n",
    "#        , NUM'TotalBsmtSF', , NUM'GrLivArea', u'BsmtFullBath', u'BsmtHalfBath',\n",
    "#        u'FullBath', u'HalfBath', u'Bedroom', u'Kitchen', u'TotRmsAbvGrd',\n",
    "#        u'GarageType', u'GarageYrBlt', u'GarageCars', NUM'GarageArea',\n",
    "#        NUM'WoodDeckSF', NUM'PoolArea'DD, NUM'MiscVal', u'MoSold', u'YrSold',\n",
    "#        u'SaleType', u'SaleCondition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 2. Determine any value of *changeable* property characteristics unexplained by the *fixed* ones.\n",
    "\n",
    "---\n",
    "\n",
    "Now that you have a model that estimates the price of a house based on its static characteristics, we can move forward with part 2 and 3 of the plan: what are the costs/benefits of quality, condition, and renovations?\n",
    "\n",
    "There are two specific requirements for these estimates:\n",
    "1. The estimates of effects must be in terms of dollars added or subtracted from the house value. \n",
    "2. The effects must be on the variance in price remaining from the first model.\n",
    "\n",
    "The residuals from the first model (training and testing) represent the variance in price unexplained by the fixed characteristics. Of that variance in price remaining, how much of it can be explained by the easy-to-change aspects of the property?\n",
    "\n",
    "---\n",
    "\n",
    "**Your goals:**\n",
    "1. Evaluate the effect in dollars of the renovate-able features. \n",
    "- How would your company use this second model and its coefficients to determine whether they should buy a property or not? Explain how the company can use the two models you have built to determine if they can make money. \n",
    "- Investigate how much of the variance in price remaining is explained by these features.\n",
    "- Do you trust your model? Should it be used to evaluate which properties to buy and fix up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: Sub setting df into unfixed characteristics\n",
    "\n",
    "unfixed = []\n",
    "for f in house_res.columns:\n",
    "    if f not in fixed_char:\n",
    "        unfixed.append(f)\n",
    "    else:\n",
    "        print f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unfixed.append('YrSold')\n",
    "unfixed.append('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df with unfixed characteristics only\n",
    "houseres2 = house_res.loc[:,unfixed]\n",
    "houseres2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in unfixed:\n",
    "    sns.barplot(x=houseres2[f].value_counts().index, y= houseres2[f].value_counts())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on plots remove columns: Street, RoofStyle, RoofMatl, ExterCond, BsmtCond, BsmtFinType2, Heating, \n",
    "# CentralAir, Electrical, Functional, GarageQual, GarageCond, PavedDrive \n",
    "['OverallQual', 'OverallCond', 'YearBuilt', 'Exterior1st',\\\n",
    "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'Foundation', 'BsmtQual',\\\n",
    "       'BsmtExposure', 'BsmtFinType1', 'HeatingQC',\\\n",
    "       'KitchenQual', 'Fireplaces', 'GarageFinish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "houseres2 = houseres2.drop(['Street', 'RoofStyle', 'RoofMatl', 'ExterCond', 'BsmtCond',\\\n",
    "                            'BsmtFinType2', 'Heating', 'CentralAir', 'Electrical', 'Functional', 'GarageQual',\\\n",
    "                            'GarageCond', 'PavedDrive'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseres2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcol2 = ['OverallQual', 'OverallCond', 'YearBuilt', 'Exterior1st',\\\n",
    "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'Foundation', 'BsmtQual',\\\n",
    "       'BsmtExposure', 'BsmtFinType1', 'HeatingQC',\\\n",
    "       'KitchenQual', 'Fireplaces', 'GarageFinish']\n",
    "for f in catcol2:\n",
    "    print f, houseres2[f].nunique()\n",
    "    \n",
    "# Note that Yearbuilt, exterior1st and 2nd have many categories. Binarise these columns for more \n",
    "# meaningful interpretation. Year built has a mean of 1972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseres2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseres2['Exterior1st'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BINARISE YEARBUILT AND EXT 1 and 2\n",
    "houseres2['yearbuilt_bef1972'] = houseres2['YearBuilt'].map(lambda x: 1 if x<1972 else 0)\n",
    "houseres2['Exterior1st_Vinyl'] = houseres2['Exterior1st'].map(lambda x: 1 if x == 'VinylSd' else 0)\n",
    "houseres2['Exterior2nd_Vinyl'] = houseres2['Exterior2nd'].map(lambda x: 1 if x == 'VinylSd' else 0)\n",
    "# houseres2.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "houseres2 = houseres2.drop(['YearBuilt','Exterior1st','Exterior2nd'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "houseres2 = pd.get_dummies(houseres2, columns=['OverallQual', u'OverallCond', u'MasVnrType', u'ExterQual',\\\n",
    "       'Foundation', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1',\\\n",
    "       'HeatingQC', 'KitchenQual', 'Fireplaces',\\\n",
    "       'GarageFinish', 'yearbuilt_bef1972',\\\n",
    "       'Exterior1st_Vinyl', 'Exterior2nd_Vinyl'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houseres2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = house_res1['SalePrice'].values\n",
    "X = house_res1.drop(['SalePrice','YrSold'],axis=1)\n",
    "Xs = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = lasso.predict(Xs)\n",
    "y_resi = y_pred - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "houseres2['y_resi'] = y_resi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split based on year sold\n",
    "traindf = houseres2[houseres2['YrSold']!=2010]\n",
    "testdf = houseres2[houseres2['YrSold']==2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = traindf['y_resi'].values\n",
    "X = traindf.drop(['YrSold', 'SalePrice', 'y_resi','BsmtUnfSF'],axis=1)\n",
    "Xs = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=optimal_lasso.alpha_)\n",
    "\n",
    "lasso_scores = cross_val_score(lasso, Xs, y, cv=5)\n",
    "\n",
    "print lasso_scores\n",
    "print np.mean(lasso_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs = pd.DataFrame({'variable':X.columns,\n",
    "                            'coef':lasso.coef_,\n",
    "                            'abs_coef':np.abs(lasso.coef_)})\n",
    "\n",
    "lasso_coefs.sort_values('abs_coef', inplace=True, ascending=False)\n",
    "\n",
    "lasso_coefs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Percent variables zeroed out:', np.sum((lasso.coef_ == 0))/float(Xs.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = testdf['y_resi'].values\n",
    "X1 = testdf.drop(['YrSold', 'SalePrice', 'y_resi','BsmtUnfSF'],axis=1)\n",
    "Xs1 = ss.transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores on test set\n",
    "lasso_scores = cross_val_score(lasso, Xs1, y1, cv=5)\n",
    "\n",
    "print lasso_scores\n",
    "print np.mean(lasso_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use lasso regression to find top 10 coefficients for unfixed characteristics\n",
    "y2 = traindf['SalePrice'].values\n",
    "X2 = traindf.drop(['YrSold', 'SalePrice', 'y_resi','BsmtUnfSF'],axis=1)\n",
    "Xs2 = ss.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=optimal_lasso.alpha_)\n",
    "\n",
    "lasso_scores = cross_val_score(lasso, Xs2, y2, cv=5)\n",
    "\n",
    "print lasso_scores\n",
    "print np.mean(lasso_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(Xs2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs = pd.DataFrame({'variable':X2.columns,\n",
    "                            'coef':lasso.coef_,\n",
    "                            'abs_coef':np.abs(lasso.coef_)})\n",
    "\n",
    "lasso_coefs.sort_values('abs_coef', inplace=True, ascending=False)\n",
    "\n",
    "lasso_coefs.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 3. What property characteristics predict an \"abnormal\" sale?\n",
    "\n",
    "---\n",
    "\n",
    "The `SaleCondition` feature indicates the circumstances of the house sale. From the data file, we can see that the possibilities are:\n",
    "\n",
    "       Normal\tNormal Sale\n",
    "       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n",
    "       AdjLand\tAdjoining Land Purchase\n",
    "       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n",
    "       Family\tSale between family members\n",
    "       Partial\tHome was not completed when last assessed (associated with New Homes)\n",
    "       \n",
    "One of the executives at your company has an \"in\" with higher-ups at the major regional bank. His friends at the bank have made him a proposal: if he can reliably indicate what features, if any, predict \"abnormal\" sales (foreclosures, short sales, etc.), then in return the bank will give him first dibs on the pre-auction purchase of those properties (at a dirt-cheap price).\n",
    "\n",
    "He has tasked you with determining (and adequately validating) which features of a property predict this type of sale. \n",
    "\n",
    "---\n",
    "\n",
    "**Your task:**\n",
    "1. Determine which features predict the `Abnorml` category in the `SaleCondition` feature.\n",
    "- Justify your results.\n",
    "\n",
    "This is a challenging task that tests your ability to perform classification analysis in the face of severe class imbalance. You may find that simply running a classifier on the full dataset to predict the category ends up useless: when there is bad class imbalance classifiers often tend to simply guess the majority class.\n",
    "\n",
    "It is up to you to determine how you will tackle this problem. I recommend doing some research to find out how others have dealt with the problem in the past. Make sure to justify your solution. Don't worry about it being \"the best\" solution, but be rigorous.\n",
    "\n",
    "Be sure to indicate which features are predictive (if any) and whether they are positive or negative predictors of abnormal sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n",
    "house_res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_res.SaleCondition.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_res['abnotab'] = house_res['SaleCondition'].map(lambda x: 1 if x =='Abnorml' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_res = house_res.drop(['Id','YearBuilt', 'YearRemodAdd','GarageYrBlt','MiscVal', 'MoSold', 'YrSold'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_res = house_res.drop(['BsmtFinType2', 'BsmtFinSF2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housedum = pd.get_dummies(house_res, columns=['MSSubClass', 'MSZoning', 'Street',\\\n",
    "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\\\n",
    "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\\\n",
    "       'HouseStyle', 'OverallQual', 'OverallCond', 'RoofStyle',\\\n",
    "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\\\n",
    "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\\\n",
    "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\\\n",
    "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical','BsmtFullBath',\\\n",
    "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\\\n",
    "       'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional',\\\n",
    "       'Fireplaces', 'GarageType', 'GarageFinish', 'GarageCars',\\\n",
    "       'GarageQual', 'GarageCond', 'PavedDrive',\\\n",
    "       'SaleType'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housedum = housedum.drop(['SaleCondition'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = housedum['abnotab'].values\n",
    "X = housedum.drop(['abnotab'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=16125986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.DataFrame(data=X_train,columns=housedum.drop(['abnotab'],axis=1).columns)\n",
    "xtrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get values of correlation for abnotab vs all\n",
    "listname = []\n",
    "listcorr = []\n",
    "for col in xtrain.columns:\n",
    "    a = stats.spearmanr(y_train,xtrain[col].values)[0]\n",
    "    listname.append(col)\n",
    "    listcorr.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist = zip(listname, listcorr)\n",
    "sorted(newlist,key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfa = pd.DataFrame(newlist,columns=['key','corr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find attributes that have corr with label that are +/- 2 s.d. away from mean of corr\n",
    "meancorr = np.mean(dfa['corr'])\n",
    "stdcorr = np.std(dfa['corr'])\n",
    "print meancorr, meancorr + 2*stdcorr, meancorr - 2*stdcorr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfa['lab'] = dfa['corr'].map(lambda x: 1 if x <= -0.0941970568899 or x >= 0.097109299639 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dfa.lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa[dfa['lab']==1].key.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'penalty':['l1','l2'] ,\\\n",
    "         'C': list(np.linspace(0.1,1,num=10))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(LogisticRegression(),param, cv=5)\n",
    "clf.fit(X_res,y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print classification_report_imbalanced(y_test, y_pred,target_names=['normal','abnormal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
