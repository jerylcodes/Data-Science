{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter nbconvert file.ipynb --toslides --post serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\envs\\py3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda2\\envs\\py3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, cv2\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import h5py\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation.\n",
    "Access files in file directory, and convert images to matrix containing pixel RGB values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeryl\\Documents\\Capstone\\20180305 Capstone\n"
     ]
    }
   ],
   "source": [
    "# Declaring img rows and cols (pixels)\n",
    "\n",
    "img_rows= 128\n",
    "img_cols= 128\n",
    "num_channel= 3\n",
    "\n",
    "# Get current directory\n",
    "\n",
    "PATH = os.getcwd()\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image augmentation\n",
    "Using the image generator from keras, to do random transformations to images. This effectively increases number of images per label to a level that is defined (in our case 1000 images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define data path\n",
    "\n",
    "data_path = os.path.join(PATH, 'datasets', 'invitrojpg')  # Insert augment folder here\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "# Construct data dictionary of training dataset \n",
    "\n",
    "directory=[]\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    for img in img_list:\n",
    "        directory.append(int(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "class_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify source and destination paths for image generation\n",
    "src_train_dir= os.path.join(PATH,'datasets', 'insitujpg')\n",
    "dest_train_dir= os.path.join(PATH,'datasets', 'augment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 296\n",
      "7 294\n",
      "7 294\n",
      "7 294\n",
      "7 294\n",
      "6 300\n",
      "6 300\n",
      "5 300\n",
      "5 300\n",
      "5 300\n",
      "4 300\n",
      "4 300\n",
      "3 300\n",
      "3 300\n",
      "3 300\n",
      "2 300\n",
      "2 300\n"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "# Use counts for individual values, generate enough images till it hits roughly 1000\n",
    "for count in label_counts.values:\n",
    "    #nb of generations per image for this class label in order to make it size ~= class_size\n",
    "    ratio=math.floor(class_size/count)-1\n",
    "    print(count,count*(ratio+1))\n",
    "    dest_lab_dir=os.path.join(dest_train_dir,str(label_counts.index[it]))\n",
    "    src_lab_dir=os.path.join(src_train_dir,str(label_counts.index[it]))\n",
    "    if not os.path.exists(dest_lab_dir):\n",
    "        os.makedirs(dest_lab_dir)\n",
    "    for file in os.listdir(src_lab_dir):\n",
    "        img=load_img(os.path.join(src_lab_dir,file))\n",
    "        #img.save(os.path.join(dest_lab_dir,file))\n",
    "        x=img_to_array(img) \n",
    "        x=x.reshape((1,) + x.shape)\n",
    "        i=0\n",
    "        for batch in datagen.flow(x, batch_size=1,save_to_dir=dest_lab_dir, save_format='jpg'):\n",
    "            i+=1\n",
    "            if i > ratio:\n",
    "                break \n",
    "    it=it+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check distribution of labels after augmentation\n",
    "aug_label = []\n",
    "\n",
    "data_path = os.path.join(PATH,'datasets', 'conf')\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "# Construct data dictionary of training dataset \n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    for img in img_list:\n",
    "        aug_label.append(int(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2092af53978>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2092af42c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "augcount = pd.DataFrame(aug_label)\n",
    "augcount[0].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading images into 128 by 128 matrix\n",
    "Use cv2.imread to convert pixel values into 0 to 255, then divide by 255 to normalise the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "data_path = os.path.join(PATH,'datasets', 'conf')\n",
    "data_dir_list = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-0\n",
      "\n",
      "Loaded the images of dataset-1\n",
      "\n",
      "Loaded the images of dataset-10\n",
      "\n",
      "Loaded the images of dataset-11\n",
      "\n",
      "Loaded the images of dataset-12\n",
      "\n",
      "Loaded the images of dataset-13\n",
      "\n",
      "Loaded the images of dataset-14\n",
      "\n",
      "Loaded the images of dataset-15\n",
      "\n",
      "Loaded the images of dataset-16\n",
      "\n",
      "Loaded the images of dataset-2\n",
      "\n",
      "Loaded the images of dataset-3\n",
      "\n",
      "Loaded the images of dataset-4\n",
      "\n",
      "Loaded the images of dataset-5\n",
      "\n",
      "Loaded the images of dataset-6\n",
      "\n",
      "Loaded the images of dataset-7\n",
      "\n",
      "Loaded the images of dataset-8\n",
      "\n",
      "Loaded the images of dataset-9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "# Read image using cv2, then append matrix to list\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img_resize=cv2.resize(input_img,(128,128))\n",
    "        img_data_list.append(input_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# Make matrix into arrays\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle X\n",
    "pickle_out = open('X_conf','wb')\n",
    "pickle.dump(img_data, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "del img_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ylab = np.array(aug_label)\n",
    "ylab = ylab.astype('int8')\n",
    "\n",
    "# Pickle y_train\n",
    "pickle_out = open('y_conf','wb')\n",
    "pickle.dump(ylab, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "del ylab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
