{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transfer learning\n",
    "\n",
    "Source: https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/\n",
    "\n",
    "Transfer learning is the process of utilising knowledge from a particular task/domain to model for another task/domain.  \n",
    "\n",
    "cap10\n",
    "\n",
    "One approach of transfer learning is the use of pre-trained model. In this capstone project, we will utilise Google's mobilenet ConvNet model and retrain the last layer of the model to classify our 17 groceries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Retraining the pre-trained model\n",
    "Retraining the model is as simple as loading up the model in your terminal, and specifying the images that you wish to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --how_many_training_steps=500 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\\n",
    "  --output_graph=tf_files/retrained_graph.pb \\\n",
    "  --output_labels=tf_files/retrained_labels.txt \\\n",
    "  --architecture=\"${ARCHITECTURE}\" \\\n",
    "  --image_dir=tf_files/grocery-photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would define 2 functions to classify our image. We would define the first function, load_graph, to load our rerained model. The second function, read_tensor_from_image_file, will return the value of the class based on the model specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def load_graph(model_file):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(model_file, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "def read_tensor_from_image_file(file_name,\n",
    "                                input_height=299,\n",
    "                                input_width=299,\n",
    "                                input_mean=0,\n",
    "                                input_std=255):\n",
    "    input_name = \"file_reader\"\n",
    "    output_name = \"normalized\"\n",
    "    file_reader = tf.read_file(file_name, input_name)\n",
    "    if file_name.endswith(\".png\"):\n",
    "        image_reader = tf.image.decode_png(\n",
    "        file_reader, channels=3, name=\"png_reader\")\n",
    "    elif file_name.endswith(\".gif\"):\n",
    "        image_reader = tf.squeeze(\n",
    "        tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n",
    "    elif file_name.endswith(\".bmp\"):\n",
    "        image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n",
    "    else:\n",
    "        image_reader = tf.image.decode_jpeg(\n",
    "        file_reader, channels=3, name=\"jpeg_reader\")\n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0)\n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(normalized)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Load the graph (model) and labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = load_graph('../tensorflow-for-poets-2/tf_files/retrained_graph.pb')\n",
    "labels = load_labels('../tensorflow-for-poets-2/tf_files/retrained_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_height=128\n",
    "input_width=128\n",
    "input_mean=0\n",
    "input_std=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer = \"input\"\n",
    "output_layer = \"final_result\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Classifying image #1, class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Jeryl/tensorflow-for-poets-2\n"
     ]
    }
   ],
   "source": [
    "# Build confusion matrix\n",
    "import os\n",
    "PATH = os.getcwd()\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_location = os.path.join(PATH,'tf_files','conf')\n",
    "data_dir_list = os.listdir(image_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read image in folder:  8 _0_423.jpg\n",
      "read image in folder:  8 _0_602.jpg\n",
      "read image in folder:  8 web1.jpg\n",
      "read image in folder:  8 web3.jpg\n",
      "read image in folder:  8 web2.jpg\n",
      "read image in folder:  4 snick3.jpg\n",
      "read image in folder:  4 snick4.jpg\n",
      "read image in folder:  4 snick5.jpg\n",
      "read image in folder:  4 snick1.jpg\n",
      "read image in folder:  4 snick2.jpeg\n",
      "read image in folder:  11 _0_705.jpg\n",
      "read image in folder:  11 _0_2735.jpg\n",
      "read image in folder:  11 _0_2633.jpg\n",
      "read image in folder:  11 web1.jpg\n",
      "read image in folder:  11 _0_2833.jpg\n",
      "read image in folder:  6 web1.jpg\n",
      "read image in folder:  6 web4.jpg\n",
      "read image in folder:  12 _0_125.jpg\n",
      "read image in folder:  12 _0_83.jpg\n",
      "read image in folder:  12 web1.jpg\n",
      "read image in folder:  12 _0_1551.jpg\n",
      "read image in folder:  12 web2.jpg\n",
      "read image in folder:  15 web5.jpg\n",
      "read image in folder:  15 _0_1843.jpg\n",
      "read image in folder:  15 _0_1176.jpg\n",
      "read image in folder:  15 _0_1219.jpg\n",
      "read image in folder:  15 web3.jpg\n",
      "read image in folder:  0 wiggly4.jpg\n",
      "read image in folder:  0 wiggly1.jpg\n",
      "read image in folder:  0 wiggly5.jpg\n",
      "read image in folder:  0 wiggly2.jpg\n",
      "read image in folder:  0 wiggly3.jpg\n",
      "read image in folder:  10 _0_1686.jpg\n",
      "read image in folder:  10 _0_1186.jpg\n",
      "read image in folder:  10 _0_1655.jpg\n",
      "read image in folder:  10 _0_1353.jpg\n",
      "read image in folder:  10 web3.jpg\n",
      "read image in folder:  5 tic2.jpg\n",
      "read image in folder:  5 tic3.jpg\n",
      "read image in folder:  5 tic1.jpg\n",
      "read image in folder:  5 tic4.jpg\n",
      "read image in folder:  5 tic5.jpg\n",
      "read image in folder:  3 twix1.jpg\n",
      "read image in folder:  3 twix2.jpg\n",
      "read image in folder:  3 twix5.jpg\n",
      "read image in folder:  3 twix3.jpg\n",
      "read image in folder:  3 twix4.jpg\n",
      "read image in folder:  14 _0_2560.jpg\n",
      "read image in folder:  14 _0_3207.jpg\n",
      "read image in folder:  14 web3.jpg\n",
      "read image in folder:  14 _0_2213.jpg\n",
      "read image in folder:  14 web2.jpg\n",
      "read image in folder:  7 star4.jpg\n",
      "read image in folder:  7 web5.jpg\n",
      "read image in folder:  7 web4.jpg\n",
      "read image in folder:  7 web6.jpg\n",
      "read image in folder:  7 star6.jpg\n",
      "read image in folder:  7 star5.jpg\n",
      "read image in folder:  13 _0_1744.jpg\n",
      "read image in folder:  13 _0_3052.jpg\n",
      "read image in folder:  13 web1.jpg\n",
      "read image in folder:  13 web2.jpg\n",
      "read image in folder:  13 _0_552.jpg\n",
      "read image in folder:  16 _0_3631.jpg\n",
      "read image in folder:  16 web4.jpg\n",
      "read image in folder:  16 web2.jpg\n",
      "read image in folder:  16 _0_3471.jpg\n",
      "read image in folder:  16 _0_3073.jpg\n",
      "read image in folder:  9 web5.jpg\n",
      "read image in folder:  9 web1.jpg\n",
      "read image in folder:  9 web3.jpg\n",
      "read image in folder:  9 web6.jpg\n",
      "read image in folder:  9 web2.jpg\n",
      "read image in folder:  1 bigred2.jpg\n",
      "read image in folder:  1 bigred4.jpg\n",
      "read image in folder:  1 bigred1.jpg\n",
      "read image in folder:  1 bigred1.png\n",
      "read image in folder:  1 bigred3.jpg\n",
      "read image in folder:  1 bigred5.jpeg\n",
      "read image in folder:  2 hers2.jpeg\n",
      "read image in folder:  2 hers4.jpg\n",
      "read image in folder:  2 hers1.jpg\n",
      "read image in folder:  2 hers1.png\n",
      "read image in folder:  2 hers3.JPG\n",
      "read image in folder:  2 hers4.png\n",
      "read image in folder:  2 hers5.jpg\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "for dataset in data_dir_list:\n",
    "    img_folder=os.path.join(image_location,dataset)\n",
    "    img_dir = os.listdir(img_folder)\n",
    "    for img in img_dir:\n",
    "        file_name= os.path.join(image_location,dataset,img)\n",
    "        t = read_tensor_from_image_file(\n",
    "              file_name,\n",
    "              input_height=input_height,\n",
    "              input_width=input_width,\n",
    "              input_mean=input_mean,\n",
    "              input_std=input_std)\n",
    "\n",
    "        input_name = \"import/\" + input_layer\n",
    "        output_name = \"import/\" + output_layer\n",
    "        input_operation = graph.get_operation_by_name(input_name)\n",
    "        output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            results = sess.run(output_operation.outputs[0], {\n",
    "                input_operation.outputs[0]: t\n",
    "            })\n",
    "            results = np.squeeze(results)\n",
    "\n",
    "        top_k = results.argsort()[-5:][::-1]\n",
    "        print('read image in folder: ', dataset, img)\n",
    "        y_pred.append(labels[top_k[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 8, 8, 11, 11, 13, 13, 14, 7, 9, 11, 11, 11, 11, 11, 13, 13, 12, 12, 12, 12, 12, 11, 15, 15, 15, 11, 11, 11, 7, 11, 7, 10, 10, 10, 10, 10, 5, 5, 5, 5, 5, 13, 7, 14, 14, 10, 14, 14, 14, 14, 14, 11, 14, 11, 7, 7, 14, 13, 13, 13, 13, 13, 16, 16, 11, 16, 16, 11, 14, 14, 11, 14, 11, 11, 14, 14, 5, 11, 14, 12, 4, 4, 11, 12, 14]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = []\n",
    "for i in y_pred:\n",
    "    Y_pred.append(int(i))\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "Y_pred = np.array(Y_pred)\n",
    "Y_pred = Y_pred.astype('int8')\n",
    "\n",
    "# Pickle y_train\n",
    "pickle_out = open('trfconf','wb')\n",
    "pickle.dump(Y_pred, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "del Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8', '8', '8', '8', '8', '4', '4', '4', '4', '4', '11', '11', '11', '11', '11', '6', '6', '12', '12', '12', '12', '12', '15', '15', '15', '15', '15', '0', '0', '0', '0', '0', '10', '10', '10', '10', '10', '5', '5', '5', '5', '5', '3', '3', '3', '3', '3', '14', '14', '14', '14', '14', '7', '7', '7', '7', '7', '7', '13', '13', '13', '13', '13', '16', '16', '16', '16', '16', '9', '9', '9', '9', '9', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "# getting true class\n",
    "conftrue = []\n",
    "for dataset in data_dir_list:\n",
    "    img_folder=os.path.join(image_location,dataset)\n",
    "    img_dir = os.listdir(img_folder)\n",
    "    for img in img_dir:\n",
    "        conftrue.append(dataset)\n",
    "print(conftrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conftrue2 = []\n",
    "for i in conftrue:\n",
    "    conftrue2.append(int(i))\n",
    "\n",
    "conftrue2 = np.array(conftrue2)\n",
    "conftrue2 = conftrue2.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle y_train\n",
    "pickle_out = open('conftrue','wb')\n",
    "pickle.dump(conftrue2, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class for your image is:  2\n"
     ]
    }
   ],
   "source": [
    "file_name= '../tensorflow-for-poets-2/tf_files/augment/2/_0_1146.jpg'\n",
    "t = read_tensor_from_image_file(\n",
    "      file_name,\n",
    "      input_height=input_height,\n",
    "      input_width=input_width,\n",
    "      input_mean=input_mean,\n",
    "      input_std=input_std)\n",
    "\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "    })\n",
    "    results = np.squeeze(results)\n",
    "\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "\n",
    "print('Predicted class for your image is: ', labels[top_k[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  3, 12, 15,  8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Classifying image #2, class 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "../tensorflow-for-poets-2/tf_files/augment/class5.jpg; No such file or directory\n\t [[Node: file_reader_15 = ReadFile[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](file_reader_15/filename)]]\n\nCaused by op 'file_reader_15', defined at:\n  File \"/home/Jeryl/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-6ff357942257>\", line 7, in <module>\n    input_std=input_std)\n  File \"<ipython-input-1-b988c08d881a>\", line 30, in read_tensor_from_image_file\n    file_reader = tf.read_file(file_name, input_name)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 376, in read_file\n    \"ReadFile\", filename=filename, name=name)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): ../tensorflow-for-poets-2/tf_files/augment/class5.jpg; No such file or directory\n\t [[Node: file_reader_15 = ReadFile[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](file_reader_15/filename)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ../tensorflow-for-poets-2/tf_files/augment/class5.jpg; No such file or directory\n\t [[Node: file_reader_15 = ReadFile[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](file_reader_15/filename)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6ff357942257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0minput_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       input_std=input_std)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"import/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b988c08d881a>\u001b[0m in \u001b[0;36mread_tensor_from_image_file\u001b[0;34m(file_name, input_height, input_width, input_mean, input_std)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_mean\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_std\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: ../tensorflow-for-poets-2/tf_files/augment/class5.jpg; No such file or directory\n\t [[Node: file_reader_15 = ReadFile[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](file_reader_15/filename)]]\n\nCaused by op 'file_reader_15', defined at:\n  File \"/home/Jeryl/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-6ff357942257>\", line 7, in <module>\n    input_std=input_std)\n  File \"<ipython-input-1-b988c08d881a>\", line 30, in read_tensor_from_image_file\n    file_reader = tf.read_file(file_name, input_name)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 376, in read_file\n    \"ReadFile\", filename=filename, name=name)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/Jeryl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): ../tensorflow-for-poets-2/tf_files/augment/class5.jpg; No such file or directory\n\t [[Node: file_reader_15 = ReadFile[_device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](file_reader_15/filename)]]\n"
     ]
    }
   ],
   "source": [
    "file_name= '../tensorflow-for-poets-2/tf_files/augment/class5.jpg'\n",
    "t = read_tensor_from_image_file(\n",
    "      file_name,\n",
    "      input_height=input_height,\n",
    "      input_width=input_width,\n",
    "      input_mean=input_mean,\n",
    "      input_std=input_std)\n",
    "\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "    })\n",
    "    results = np.squeeze(results)\n",
    "\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Classifying image #3, class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.450499\n",
      "11 0.270105\n",
      "13 0.13487\n",
      "15 0.0740191\n",
      "16 0.0211695\n"
     ]
    }
   ],
   "source": [
    "file_name= '../tensorflow-for-poets-2/tf_files/augment/class3.jpg'\n",
    "t = read_tensor_from_image_file(\n",
    "      file_name,\n",
    "      input_height=input_height,\n",
    "      input_width=input_width,\n",
    "      input_mean=input_mean,\n",
    "      input_std=input_std)\n",
    "\n",
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    results = sess.run(output_operation.outputs[0], {\n",
    "        input_operation.outputs[0]: t\n",
    "    })\n",
    "    results = np.squeeze(results)\n",
    "\n",
    "top_k = results.argsort()[-5:][::-1]\n",
    "\n",
    "for i in top_k:\n",
    "    print(labels[i], results[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Image classification using deep learning can have significant impacts on society. In order to build a successful image classifier, we would need to establish a robust model for classification. The robustness of the model can be tweaked by the various hyper-parameters in the particular model of choice.  \n",
    "\n",
    "In this project, we have explored using the vanilla ConvNet architecture as well as a pre-trained ConvNet architecture made available by Google through transfer learning. In the vanilla ConvNet architecture, we have seen how we could tweak the architecture based on our preferences. On the other hand, we have also observed from transfer learning, the ease at which businesses can employ pre-existing models to help with their image classification problems.  \n",
    "\n",
    "In my personal opinion, I would advise businesses to take a look at their dataset before considering to build their own model for classification. Businesses can then pick and choose their best model based on their needs. Here are some advantages of both methods:  \n",
    "  \n",
    "  \n",
    "**1. Build ConvNet from scratch**\n",
    "- Full control of hyper-parameters\n",
    "- Full control of trainable features, depth and complexity of the model  \n",
    "\n",
    "**2.  Transfer learning **\n",
    "- Easy to apply\n",
    "- Models from different domains may be applicable to business use cases from differing domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future work\n",
    "1. Explore other techniques to classify images: Support Vector Machines, Fuzzy measures and Genetic Algorithms\n",
    "2. Build application for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
